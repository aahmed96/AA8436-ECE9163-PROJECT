{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AA8436-Final-Project.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pruning Models to prevent Backdoor attacks"
      ],
      "metadata": {
        "id": "1qqzIuX1ur31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries, cloning github repo and downloading datasets"
      ],
      "metadata": {
        "id": "mC3k0XEbuylN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX36UKuucRhZ"
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "import h5py\n",
        "import matplotlib.image as mpimg\n",
        "import imageio as im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HO7Zpgqc-zV"
      },
      "source": [
        "Clone the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-grKD70c7dB",
        "outputId": "04de97fc-8452-4779-e745-dabd2905f876"
      },
      "source": [
        "! git clone https://github.com/csaw-hackml/CSAW-HackML-2020.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSAW-HackML-2020'...\n",
            "remote: Enumerating objects: 220, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 220 (delta 27), reused 2 (delta 0), pack-reused 164\u001b[K\n",
            "Receiving objects: 100% (220/220), 85.94 MiB | 28.83 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kao_cldDdzhA"
      },
      "source": [
        "Download the datasets from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrbXkwSEb2lL",
        "outputId": "890c5060-9ced-4572-82fb-3961966fda30"
      },
      "source": [
        "%cd /content/CSAW-HackML-2020/data\n",
        "%mkdir data\n",
        "\n",
        "#download datasets\n",
        "!gdown --id 19OKCkY2CjV3ASkOe6nMSYTsOVcxAoCnA\n",
        "!gdown --id 1XtYnM-IopU-QYVc99U51EiDvI5zxK0nV\n",
        "!gdown --id 1P8PTL62x3cfpV9mrC0unqZjRFhlTTOSG\n",
        "!gdown --id 1XFKaTse6gflUFK7lDPxXBUaq4oQA8-qy\n",
        "!gdown --id 1TiBviHoi-nh-aDRCP-1ZQlP0Nis6wOCw\n",
        "!gdown --id 1SrObV38DPLgsMfpPYTdeX7nzjrEUAEwW"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSAW-HackML-2020/data\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19OKCkY2CjV3ASkOe6nMSYTsOVcxAoCnA\n",
            "To: /content/CSAW-HackML-2020/data/clean_validation_data.h5\n",
            "100% 716M/716M [00:02<00:00, 302MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XtYnM-IopU-QYVc99U51EiDvI5zxK0nV\n",
            "To: /content/CSAW-HackML-2020/data/clean_test_data.h5\n",
            "100% 398M/398M [00:01<00:00, 262MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1P8PTL62x3cfpV9mrC0unqZjRFhlTTOSG\n",
            "To: /content/CSAW-HackML-2020/data/sunglasses_poisoned_data.h5\n",
            "100% 398M/398M [00:02<00:00, 141MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XFKaTse6gflUFK7lDPxXBUaq4oQA8-qy\n",
            "To: /content/CSAW-HackML-2020/data/anonymous_1_poisoned_data.h5\n",
            "100% 637M/637M [00:06<00:00, 96.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TiBviHoi-nh-aDRCP-1ZQlP0Nis6wOCw\n",
            "To: /content/CSAW-HackML-2020/data/lipstick_poisoned_data.h5\n",
            "100% 637M/637M [00:03<00:00, 198MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SrObV38DPLgsMfpPYTdeX7nzjrEUAEwW\n",
            "To: /content/CSAW-HackML-2020/data/eyebrows_poisoned_data.h5\n",
            "100% 637M/637M [00:07<00:00, 80.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The BadNets"
      ],
      "metadata": {
        "id": "nxwAXTAdvACo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we do the following:\n",
        "\n",
        "\n",
        "1.   Load the badnets\n",
        "2.   Load the data\n",
        "3.   Get activations for the last CNN layer and sort it\n",
        "\n"
      ],
      "metadata": {
        "id": "7X3ahedwvJab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the model"
      ],
      "metadata": {
        "id": "RRaDPqV5vY9m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNTUMM1ddIs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184095ea-3c85-4db1-a82f-ad6dc5d687b0"
      },
      "source": [
        "%cd \n",
        "%cd /content\n",
        "\n",
        "badNetPaths = ['/content/CSAW-HackML-2020/models/anonymous_1_bd_net.h5',\n",
        "               '/content/CSAW-HackML-2020/models/anonymous_2_bd_net.h5',\n",
        "               '/content/CSAW-HackML-2020/models/multi_trigger_multi_target_bd_net.h5',\n",
        "               '/content/CSAW-HackML-2020/models/sunglasses_bd_net.h5']\n",
        "\n",
        "weightsPaths = ['/content/CSAW-HackML-2020/models/anonymous_1_bd_weights.h5',\n",
        "                '/content/CSAW-HackML-2020/models/anonymous_2_bd_weights.h5',\n",
        "                '/content/CSAW-HackML-2020/models/multi_trigger_multi_target_bd_weights.h5',\n",
        "                '/content/CSAW-HackML-2020/models/sunglasses_bd_weights.h5']\n",
        "\n",
        "def CreateModel(badnet,weights):\n",
        "  Model = keras.models.load_model(badnet)\n",
        "  loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  Model.load_weights(weights)\n",
        "  Model.compile(optimizer='adam', loss=loss_func, metrics=['accuracy'])\n",
        "  \n",
        "\n",
        "  return Model\n",
        "\n",
        "BadNetA1 = CreateModel(badNetPaths[0],weightsPaths[0])\n",
        "BadNetA2 = CreateModel(badNetPaths[1],weightsPaths[1])\n",
        "BadNetA3 = CreateModel(badNetPaths[2],weightsPaths[2])\n",
        "BadNetA4 = CreateModel(badNetPaths[3],weightsPaths[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yGyr-EEibJz"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RONdjqMJic6g"
      },
      "source": [
        "# Load validation dataset\n",
        "def loadData(filePath):\n",
        "  data = h5py.File(filePath,'r')\n",
        "  x = np.array(data['data'])\n",
        "  x = x.transpose((0,2,3,1))\n",
        "  x = x/255\n",
        "  y = np.array(data['label'])\n",
        "\n",
        "  return x,y\n",
        "\n",
        "#set paths for all datasets\n",
        "valCleanPath = '/content/CSAW-HackML-2020/data/clean_validation_data.h5'\n",
        "testCleanPath = '/content/CSAW-HackML-2020/data/clean_test_data.h5'\n",
        "valBadPaths = ['/content/CSAW-HackML-2020/data/sunglasses_poisoned_data.h5',\n",
        "               '/content/CSAW-HackML-2020/data/lipstick_poisoned_data.h5',\n",
        "               '/content/CSAW-HackML-2020/data/eyebrows_poisoned_data.h5',\n",
        "               '/content/CSAW-HackML-2020/data/anonymous_1_poisoned_data.h5']\n",
        "\n",
        "\n",
        "#load data\n",
        "valCleanX, valCleanY = loadData(valCleanPath)\n",
        "\n",
        "\n",
        "\n",
        "testCleanX, testCleanY = loadData(testCleanPath)\n",
        "valBadSunGlassesX, valBadSunGlassesY = loadData(valBadPaths[0])\n",
        "valBadLipstickX, valBadLipstickY = loadData(valBadPaths[1])\n",
        "valBadEyebrowsX, valBadEyeBrowsY = loadData(valBadPaths[2])\n",
        "valBadA1X, valBadA2Y = loadData(valBadPaths[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing Activations"
      ],
      "metadata": {
        "id": "Yqrg-vbYwiWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ComputeActivation(badNet,valCleanX):\n",
        "  layer = badNet.layers[5].output\n",
        "  activationModel = models.Model(inputs=badNet.input, outputs=layer)\n",
        "  layerActivations = activationModel.predict(valCleanX)\n",
        "\n",
        "  imageNum = layerActivations.shape[0]\n",
        "  chanelActivations = np.zeros([10, 8, 60])\n",
        "  #set chanel activations\n",
        "  for image in range(imageNum): #go through all images \n",
        "    chanelActivations[:,:,:] += layerActivations[image,:,:,:]\n",
        "\n",
        "  chanelActivations = chanelActivations/imageNum\n",
        "\n",
        "  #compute average activation for each chanel\n",
        "  averageChanelActivation = []\n",
        "  for chanel in range(60): #there are 60 chanels\n",
        "    activation = np.sum(chanelActivations[:,:,chanel]/80)\n",
        "    averageChanelActivation.append(activation)\n",
        "\n",
        "  #sort activations in ascending order while maintaining an index of chanels\n",
        "  activationRef = dict() #create an empty dict\n",
        "\n",
        "  for idx,value in enumerate(averageChanelActivation):\n",
        "    activationRef[idx] = value\n",
        "\n",
        "  sortedAct = sorted(activationRef.items(), key=lambda x: x[1])\n",
        "\n",
        "  return sortedAct\n",
        "\n",
        "sortedActA1 = ComputeActivation(BadNetA1,valCleanX)\n",
        "sortedActA2 = ComputeActivation(BadNetA2,valCleanX)\n",
        "sortedActA3 = ComputeActivation(BadNetA3,valCleanX)\n",
        "sortedActA4 = ComputeActivation(BadNetA4,valCleanX)"
      ],
      "metadata": {
        "id": "SBVNteirwZ0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning the Badnet: Creating Repaired Networks"
      ],
      "metadata": {
        "id": "voK4_wqgdPNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let us now finally get to pruning\n",
        "#we will prune on validation data\n",
        "def pruneModel(targetAcc,RepairedModel,valCleanX,valCleanY,testBadX,testBadY,sortedActivations):\n",
        "  #targetAcc is given as either 0.02, 0.04 or 0.10 \n",
        "  #RepairedModel = keras.models.load_model(path)\n",
        "  #RepairedModel.compile(optimizer = 'adam',loss = loss_func,metrics=['accuracy'])\n",
        "\n",
        "  weights,biases = RepairedModel.layers[5].get_weights()\n",
        "\n",
        "  baseLoss, baseAcc = RepairedModel.evaluate(valCleanX,valCleanY,verbose=2)\n",
        "  threshold = 0\n",
        "  run = 0\n",
        "  for i in range(60): #number of chanels to prune\n",
        "\n",
        "    index = sortedActivations[i][0]\n",
        "    weights[:,:,:,index] = np.zeros((3,3,40)) #setting weights to zero\n",
        "    biases[index] = 0 #setting biase to zero \n",
        "    RepairedModel.layers[5].set_weights([weights,biases])\n",
        "    newLoss, newAcc = RepairedModel.evaluate(valCleanX,valCleanY,verbose=2)\n",
        "    threshold = baseAcc - newAcc\n",
        "    run+=1\n",
        "    \n",
        "    if threshold >= targetAcc:\n",
        "      break\n",
        "  \n",
        "  chanelsPrunedFraction = run/60\n",
        "  repLoss, repAcc = RepairedModel.evaluate(valCleanX,valCleanY,verbose=2)\n",
        "  a, attackSuccess = RepairedModel.evaluate(testBadX, testBadY, verbose=0)\n",
        "\n",
        "  return RepairedModel, chanelsPrunedFraction, repAcc, attackSuccess"
      ],
      "metadata": {
        "id": "4uCmBWtlM6h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RepairedNetA1, chanelsPrunedFractionA1, repAccA1, attackSuccessA1 = pruneModel(0.15,\n",
        "                                                                               BadNetA1,\n",
        "                                                                               valCleanX,valCleanY,\n",
        "                                                                               valBadA1X,valBadA2Y,\n",
        "                                                                               sortedActA1)\n",
        "\n",
        "RepairedNetA2, chanelsPrunedFractionA2, repAccA2, attackSuccessA2 = pruneModel(0.15,\n",
        "                                                                               BadNetA2,\n",
        "                                                                               valCleanX,valCleanY,\n",
        "                                                                               valBadA1X,valBadA2Y,\n",
        "                                                                               sortedActA2)\n",
        "\n",
        "RepairedNetA3, chanelsPrunedFractionA3, repAccA3, attackSuccessA3 = pruneModel(0.15,\n",
        "                                                                               BadNetA3,\n",
        "                                                                               valCleanX,valCleanY,\n",
        "                                                                               valBadEyebrowsX,valBadEyeBrowsY,\n",
        "                                                                               sortedActA3)\n",
        "\n",
        "RepairedNetA4, chanelsPrunedFractionA4, repAccA4, attackSuccessA4 = pruneModel(0.15,\n",
        "                                                                               BadNetA4,\n",
        "                                                                               valCleanX,valCleanY,\n",
        "                                                                               valBadSunGlassesX,valBadSunGlassesY,\n",
        "                                                                               sortedActA4)"
      ],
      "metadata": {
        "id": "wUL5p2tzhkZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we save the repaired models"
      ],
      "metadata": {
        "id": "-Wwwb9JnmyuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RepairedNetA1.save('RepairedNetA1')\n",
        "RepairedNetA2.save('RepairedNetA2')\n",
        "RepairedNetA3.save('RepairedNetA3')\n",
        "RepairedNetA4.save('RepairedNetA4')"
      ],
      "metadata": {
        "id": "cD2HINlam1za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, we also save the badnets for reference."
      ],
      "metadata": {
        "id": "WcHQdsJLIVz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BadNetA1.save('BadNetA1')\n",
        "BadNetA2.save('BadNetA2')\n",
        "BadNetA3.save('BadNetA3')\n",
        "BadNetA4.save('BadNetA4')"
      ],
      "metadata": {
        "id": "y0YCKm-UISnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('For our A1 repaired model, we have the following metrics:')\n",
        "print('Fraction of chanels pruned: ',chanelsPrunedFractionA1)\n",
        "print('Accuracy on the clean validation dataset: ', repAccA1)\n",
        "print('Attack success rate: ',attackSuccessA1)\n",
        "print('------------------------------------------------------')\n",
        "\n",
        "print('For our A2 repaired model, we have the following metrics:')\n",
        "print('Fraction of chanels pruned: ',chanelsPrunedFractionA2)\n",
        "print('Accuracy on the clean validation dataset: ', repAccA2)\n",
        "print('Attack success rate: ',attackSuccessA2)\n",
        "print('------------------------------------------------------')\n",
        "\n",
        "print('For our A3 repaired model, we have the following metrics:')\n",
        "print('Fraction of chanels pruned: ',chanelsPrunedFractionA3)\n",
        "print('Accuracy on the clean validation dataset: ', repAccA3)\n",
        "print('Attack success rate: ',attackSuccessA3)\n",
        "print('------------------------------------------------------')\n",
        "\n",
        "print('For our A4 repaired model, we have the following metrics:')\n",
        "print('Fraction of chanels pruned: ',chanelsPrunedFractionA4)\n",
        "print('Accuracy on the clean validation dataset: ', repAccA4)\n",
        "print('Attack success rate: ',attackSuccessA4)\n",
        "print('------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX93tXwmh_-5",
        "outputId": "b3fdbf70-c70d-4e92-c497-2a4b07af216b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For our A1 repaired model, we have the following metrics:\n",
            "Fraction of chanels pruned:  0.5666666666666667\n",
            "Accuracy on the clean validation dataset:  0.8118125796318054\n",
            "Attack success rate:  0.6192517280578613\n",
            "------------------------------------------------------\n",
            "For our A2 repaired model, we have the following metrics:\n",
            "Fraction of chanels pruned:  0.5166666666666667\n",
            "Accuracy on the clean validation dataset:  0.7880834937095642\n",
            "Attack success rate:  0.0\n",
            "------------------------------------------------------\n",
            "For our A3 repaired model, we have the following metrics:\n",
            "Fraction of chanels pruned:  0.55\n",
            "Accuracy on the clean validation dataset:  0.803412139415741\n",
            "Attack success rate:  0.8066056370735168\n",
            "------------------------------------------------------\n",
            "For our A4 repaired model, we have the following metrics:\n",
            "Fraction of chanels pruned:  0.5833333333333334\n",
            "Accuracy on the clean validation dataset:  0.82792067527771\n",
            "Attack success rate:  0.9855027198791504\n",
            "------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GoodNet"
      ],
      "metadata": {
        "id": "BHsAf4PIl2ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the goodnet, we will simply feed the network with test image and compare the outputs. If outputs do not match, then we will assign N+1 as the prediction"
      ],
      "metadata": {
        "id": "R45tB7_Fl5ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "#input the paths\n",
        "repairedNetPath = ''\n",
        "badNetPath = ''\n",
        "testImagePath = ''\n",
        "\n",
        "def imagePreProcess(imagePath):\n",
        "  image = Image.open(imagePath)\n",
        "  imageArray = np.asarray(image)\n",
        "  imageArray = np.float32(imageArray)\n",
        "  imageTensor = tf.convert_to_tensor(imageArray)\n",
        "  imageTensor = tf.expand_dims(imageTensor, 0)\n",
        "  imageTensor = imageTensor/255\n",
        "\n",
        "  return imageTensor\n",
        "\n",
        "def Goodnet(testImagePath,badNetPath,repairedNetPath):\n",
        "  testImage = imagePreProcess(testImagePath)\n",
        "  repairedNet = keras.models.load_model(repairedNetPath)\n",
        "  badNet = keras.models.load_model(badNetPath)\n",
        "\n",
        "  predictionRNet = np.argmax(repairedNet.predict(testImage))\n",
        "  predictionBNet = np.argmax(badNet.predict(testImage))\n",
        "\n",
        "  if predictionRNet == predictionBNet:\n",
        "    prediction = predictionRNet\n",
        "    \n",
        "  else:\n",
        "    prediction = 1283\n",
        "    \n",
        "  \n",
        "  return prediction"
      ],
      "metadata": {
        "id": "NMpLgG9wl4dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir MyModels\n",
        "!zip -r /content/MyModels.zip /content/MyModels"
      ],
      "metadata": {
        "id": "-rychki_Moc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}